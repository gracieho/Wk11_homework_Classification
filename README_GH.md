# Wk11_homework_Classification
Submission of week 11 homework on Classification

In this week's assignment, loan data was reviewed which had imbalanced classes (circa 30 to 1 ratio).  A Label encoder was used to amend the categorical information to numerical, before being split into train and test datasets.  A number of different techniques were used before logistical regression was applied to the data (including no amendments, random over sampling, SMOTE oversampling, Cluster Centroids undersampling, and SMOTE ENN combination sampling.  The outcome was Random Over Sampling had the best balanced accuracy score, however, all the models had similar geometric mean scores of 0.99.  Further analysis could be performed to review the Precision-Recall curve (PRC) to determine which model performs the best across all probability classification thresholds (based on area under the PRC or AUPRC).  In the file, a comparison was made bewteen the SMOTE vs SMOTEENN AUPRC.  In this case, SMOTE perfomed marginally better.

Secondly, Loan statistics were reviewed for a particular quarter.  The data was simarly prepared using Label encoder to adjust for the categorical information, then train & test splits of the dataset was made.  An additional step was taken where the data was scaled between 0 to 1, so that it could be more easily processed by the models.  Two ensemble learning models were applied, and the outcome was the Easy Ensemble Classifier was significantly better at predicting the data than the Balanced Random Forest Cassifier.  The top 3 features for model prediction were also identified.
